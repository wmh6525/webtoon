{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comment ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "commentData = pd.read_csv('comment.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ê¸€ìì •ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_origin = commentData.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì˜ì–´ comment ì •ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ì–´ ê¸€ì í™•ì¸\n",
    "pd.set_option('display.max_rows', None)\n",
    "tmp = commentData['comment'].replace('[^a-zA-Z]','',regex=True)\n",
    "tmp[tmp.str.contains('[a-zA-Z]')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì˜ì–´ë¡œ í‘œí˜„ëœ ê°ì •í‘œí˜„ ì •ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bb -> êµ¿, zz -> ã…‹ã…‹\n",
    "commentData['comment'] = commentData['comment'].str.replace(\"Good\",\"êµ¿\")\n",
    "commentData['comment'] = commentData['comment'].str.replace(\"bb+\",\"êµ¿\")\n",
    "commentData['comment'] = commentData['comment'].str.replace(\"zz+\",\"ã…‹ã…‹\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ë‚˜ë¨¸ì§€ ì˜ì–´ ì‚­ì œ\n",
    "commentData['comment'] = commentData['comment'].replace('[a-zA-Z]','',regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ì´ëª¨í‹°ì½˜ ì •ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ëª¨í‹°ì½˜ ëŒ€ì²´\n",
    "commentData['comment'] = commentData['comment'].str.replace('[ğŸ™ƒğŸ¤£ğŸ˜†ğŸ˜€ğŸ˜ŠğŸ˜„ğŸ¤­ğŸ˜ğŸ˜‚]+','ã…‹ã…‹',regex=True)\n",
    "commentData['comment'] = commentData['comment'].str.replace('[ğŸ˜¢ğŸ˜­ğŸ¥º]+','ã… ã… ',regex=True)\n",
    "commentData['comment'] = commentData['comment'].str.replace('[ğŸ”¥ğŸ‘ŠğŸ’ª]+','íŒŒì´íŒ…',regex=True)\n",
    "commentData['comment'] = commentData['comment'].str.replace('[ğŸ‘ğŸ»ğŸ‘]+','êµ¿',regex=True)\n",
    "commentData['comment'] = commentData['comment'].str.replace('[ğŸŠğŸ‰âœ¨ğŸ‘ğŸ¥³ğŸ’]+','ì¶•í•˜',regex=True)\n",
    "commentData['comment'] = commentData['comment'].str.replace('[ğŸ’Ÿâ™¡â™¥ï¸â¤â¤ï¸ğŸ’“ğŸ’•ğŸ’–ğŸ’—ğŸ’˜ğŸ’™ğŸ’šğŸ’›ğŸ’œğŸ’ğŸ’ğŸ˜ğŸ˜˜ğŸ˜»ğŸ¤ğŸ¤ğŸ¥°ğŸ§¡ğŸ˜šğŸ’‹]+','â¤ï¸',regex=True)\n",
    "commentData['comment'] = commentData['comment'].str.replace('[â˜†â˜…â­]+','ë³„',regex=True)\n",
    "commentData['comment'] = commentData['comment'].str.replace('[ğŸª]+','ì¿ í‚¤',regex=True)\n",
    "commentData['comment'] = commentData['comment'].str.replace('[ğŸ™]+',\"ì œë°œ\",regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ììŒ ì •ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ììŒ ì •ë¦¬\n",
    "commentData['comment'] = commentData['comment'].str.replace('ã„·ã„·+','ëœëœ',regex=True)\n",
    "commentData['comment'] = commentData['comment'].str.replace('ã…ã…‡ã…Œ','íŒŒì´íŒ…',regex=True)\n",
    "commentData['comment'] = commentData['comment'].str.replace('ã…‡ã…ˆ','ì¸ì •',regex=True)\n",
    "commentData['comment'] = commentData['comment'].str.replace('ã„¹ã…ˆ','ì¸ì •',regex=True)\n",
    "commentData['comment'] = commentData['comment'].str.replace('ã…‚ã„·','ë¶€ë“¤',regex=True)\n",
    "commentData['comment'] = commentData['comment'].str.replace('ã…ã…‡ã…ã…‡','ë­ì•¼ë­ì•¼',regex=True)\n",
    "commentData['comment'] = commentData['comment'].str.replace('ã„¹ã…ˆã„·','ë ˆì „ë“œ',regex=True)\n",
    "commentData['comment'] = commentData['comment'].str.replace('ã„±ã…‡ã…‡','ê·€ì—¬ì›Œ',regex=True)\n",
    "commentData['comment'] = commentData['comment'].str.replace('ã„·ã„±','ë‘ê·¼',regex=True)\n",
    "commentData['comment'] = commentData['comment'].str.replace('ã…Šã…','ì¶•í•˜',regex=True)\n",
    "commentData['comment'] = commentData['comment'].str.replace('ã…Šã…Š','ì¶•í•˜',regex=True)\n",
    "commentData['comment'] = commentData['comment'].str.replace('ã…†ã„¹ã„±','ì“°ë ˆê¸°',regex=True)\n",
    "commentData['comment'] = commentData['comment'].str.replace('ã„±ã…‡ã„·','ì´ë“',regex=True)\n",
    "commentData['comment'] = commentData['comment'].str.replace('ã…‡ã„·','ì–´ë””',regex=True)\n",
    "commentData['comment'] = commentData['comment'].str.replace('ã…ã„¹','ëª°ë¼',regex=True)\n",
    "commentData['comment'] = commentData['comment'].str.replace('ã„±ã…Š','ê´œì°®',regex=True)\n",
    "commentData['comment'] = commentData['comment'].str.replace('ã……ã„²','ìƒˆë¼',regex=True)\n",
    "commentData['comment'] = commentData['comment'].str.replace('ã…ã…Š','ë¯¸ì¹œ',regex=True)\n",
    "commentData['comment'] = commentData['comment'].str.replace('ã…ã…+','ã…ã…',regex=True)\n",
    "commentData['comment'] = commentData['comment'].str.replace('ã…‹ã…‹+','ã…‹ã…‹',regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ëª¨ìŒ ì •ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ìŒ ì •ë¦¬\n",
    "commentData['comment'] = commentData['comment'].str.replace('ã…œ+','ã… ã… ',regex=True)\n",
    "commentData['comment'] = commentData['comment'].str.replace('ã… ã… +','ã… ã… ',regex=True)\n",
    "# í•œêµ­ì–´, ìˆ«ì, ë„ì–´ì“°ê¸°, í•˜íŠ¸ ì œì™¸ ì‚­ì œ\n",
    "commentData['comment'] = commentData['comment'].str.replace('[^0-9ã…‹ã…ã… ê°€-í£â¤ï¸ ]','',regex=True)\n",
    "## ì˜ë¯¸ê°€ ì—†ëŠ” ë‹¨ì–´ë“¤ë¡œ íŒë‹¨í•˜ì—¬ ì‚­ì œ\n",
    "com_null_idx = commentData[commentData['comment'] == ''].index\n",
    "commentData.drop(com_null_idx, inplace=True)\n",
    "commentData.reset_index(drop=True, inplace=True)\n",
    "\n",
    "commentData['comment'] = commentData['comment'].str.replace('ã…‹ã…‹',' ã…‹ã…‹ ')\n",
    "commentData['comment'] = commentData['comment'].str.replace('ã…ã…',' ã…ã… ')\n",
    "commentData['comment'] = commentData['comment'].str.replace('ã… ã… ',' ã… ã…  ')\n",
    "commentData['comment'] = commentData['comment'].str.replace(' +',' ', regex=True)\n",
    "\n",
    "for i in range(len(commentData)):\n",
    "    if commentData.loc[i,'comment'] == '': print(i) \n",
    "    elif commentData.loc[i,'comment'] == ' ': print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentData.drop([1376,4218,11756,11895,12371,13106,13293,13922,14088,19768],inplace=True)\n",
    "commentData.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. í•œì…€ êµì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install git+https://github.com/ssut/py-hanspell.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hanspell import spell_checker\n",
    "for i in range(25584,len(commentData)):\n",
    "  commentData.loc[i,'comment'] = spell_checker.check(commentData.loc[i,'comment']).checked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. í˜•íƒœì†Œ ë¶„ì„ê¸° ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
    "%cd Mecab-ko-for-Google-Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash install_mecab-ko_on_colab190912.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "from konlpy.tag import Kkma\n",
    "kkma = Kkma()\n",
    "\n",
    "from konlpy.tag import Komoran\n",
    "komoran = Komoran()\n",
    "\n",
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/haven-jeon/PyKoSpacing.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykospacing import Spacing\n",
    "spacing = Spacing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í˜•íƒœì†Œ ë¶„ì„ê¸° í›„ í•œì…€ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hanspell import spell_checker\n",
    "original_sentence = commentData.loc[20,'comment']\n",
    "original_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*okt.morphs(original_sentence, stem=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*kkma.morphs(original_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*komoran.morphs(original_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*mecab.morphs(original_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë„ì–´ì“°ê¸°\n",
    "spacing(original_sentence) # ì´ê±°ëŠ” ì‚¬ìš©x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ë§ì¶¤ë²• êµì •\n",
    "spelled_sentence = spell_checker.check(original_sentence).checked\n",
    "spelled_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*okt.morphs(spelled_sentence, stem=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*kkma.morphs(spelled_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. mecab í˜•íƒœì†Œ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
    "%cd Mecab-ko-for-Google-Colab\n",
    "!bash install_mecab-ko_on_colab190912.sh\n",
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "!apt-get update -qq\n",
    "!apt-get install fonts-nanum* -qq\n",
    "import matplotlib.font_manager as fm\n",
    "sys_font = fm.findSystemFonts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²´ì–¸, ìš©ì–¸(ë™ì‚¬, í˜•ìš©ì‚¬), ì¼ë°˜ë¶€ì‚¬, ê°íƒ„ì‚¬, ì²´ì–¸ ì ‘ë‘ì‚¬, ì–´ê·¼, ë¶€í˜¸ ë° ìˆ«ì\n",
    "goodPos = ['NNG','NNP','NNBC','NR','NP','VV','VA','MAG','IC','XPN','XR']\n",
    "  #### ì¡°ì‚¬, ì–´ë¯¸ ë“± ì˜ë¯¸ì—†ëŠ” ë‹¨ì–´ëŠ” ì¶”ì¶œí•˜ì§€ ì•ŠìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ì‹ì—°ì¬ í† í°í™”\n",
    "pubCom = commentData[commentData['isPublic'] == 1]\n",
    "\n",
    "public_mecab = []\n",
    "for sentence in pubCom['comment']:\n",
    "  tokenized_sentence = mecab.pos(sentence)\n",
    "  token = []\n",
    "  for i in range(len(tokenized_sentence)):\n",
    "    if tokenized_sentence[i][1] in goodPos:\n",
    "      token.append(tokenized_sentence[i][0])\n",
    "    elif tokenized_sentence[i][1][:2] in ['VV','VA']: # ë™ì‚¬ì™€/í˜•ìš©ì‚¬ + ì–´ë¯¸\n",
    "      token.append(tokenized_sentence[i][0])\n",
    "  public_mecab.append(token)\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(public_mecab)\n",
    "wordDict = tokenizer.word_counts\n",
    "wordDict_sorted = list(sorted(tokenizer.word_counts.items(), key=lambda x: x[1], reverse=True))\n",
    "print(len(wordDict_sorted))\n",
    "print(wordDict_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud(font_path='/usr/share/fonts/truetype/nanum/NanumGothic.ttf', background_color='white')\n",
    "gen = wc.generate_from_frequencies(wordDict)\n",
    "plt.figure()\n",
    "plt.imshow(gen)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¹„ì •ì‹ì—°ì¬ í† í°í™”\n",
    "notPubCom = commentData[commentData['isPublic'] == 0]\n",
    "\n",
    "notPublic_mecab = []\n",
    "for sentence in notPubCom['comment']:\n",
    "  tokenized_sentence = mecab.pos(sentence)\n",
    "  token = []\n",
    "  for i in range(len(tokenized_sentence)):\n",
    "    if tokenized_sentence[i][1] in goodPos:\n",
    "      token.append(tokenized_sentence[i][0])\n",
    "    elif tokenized_sentence[i][1][:2] in ['VV','VA']:\n",
    "      token.append(tokenized_sentence[i][0])\n",
    "  notPublic_mecab.append(token)\n",
    "tokenizer2 = Tokenizer()\n",
    "tokenizer2.fit_on_texts(notPublic_mecab)\n",
    "wordDict2 = tokenizer2.word_counts\n",
    "wordDict_sorted2 = list(sorted(tokenizer2.word_counts.items(), key=lambda x: x[1], reverse=True))\n",
    "print(len(wordDict_sorted2))\n",
    "print(wordDict_sorted2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud(font_path='/usr/share/fonts/truetype/nanum/NanumGothic.ttf', background_color='white')\n",
    "gen = wc.generate_from_frequencies(wordDict2)\n",
    "plt.figure()\n",
    "plt.imshow(gen)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. ë‹¨ì–´ ì„ íƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentData2 = commentData.copy()\n",
    "\n",
    "for i in range(len(commentData)):\n",
    "  sentence = commentData.loc[i,'comment']\n",
    "  if type(sentence) == float: continue\n",
    "  tokenized_sentence = mecab.pos(sentence)\n",
    "  token = ''\n",
    "  for j in range(len(tokenized_sentence)):\n",
    "    if tokenized_sentence[j][1] in goodPos:\n",
    "      token += ' '+tokenized_sentence[j][0]\n",
    "    elif tokenized_sentence[j][1][:2] in ['VV','VA']:\n",
    "      token += ' '+tokenized_sentence[j][0]\n",
    "  commentData2.loc[i,'comment'] = token\n",
    "\n",
    "#commentData2.to_csv('comment_mecab.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsList = {'ã…‹ã…‹','ì¢‹','ì •ì‹','ì¬ë°Œ','ì˜','ì—°ì¬','ë„¤ì´ë²„','ë‹¤ìŒ','ì¹œêµ¬','ì‚¬ë‘',\n",
    "             'ê·¸ë¦¼','ì‘í’ˆ','ë¹¨ë¦¬','ê°ì‚¬','ì¼','ìŠ¤í† ë¦¬','ì˜¤','ã…ã…','íŒŒì´íŒ…','ê¸°ëŒ€',\n",
    "             'ëŒ€ë°•','ê¶ê¸ˆ','ë‚¨','ì—¬ì£¼','ì—¬ì','ë°ë ¤ê°€','ì¶•í•˜','ë§ˆìŒ','ì†Œë¦„','ê¸°ë‹¤ë ¸',\n",
    "             'ê·€ì—½','ê¸°ë‹¤ë¦¬','ì†Œì›','ê³„ì†','ì˜†','ì‹œê°„','ë¯¸ì³¤','ì¡´','ë‚¨ì£¼','í–‰ë³µ','ëŠ˜',\n",
    "             'ë‹¤ì‹œ','í‘œì •','ë‚˜ìœ','ì£¼ì¸ê³µ','í€„ë¦¬í‹°','ê·€ì—¬ì›Œ','í˜ë“¤','ì‘ì›','í˜ë‚´',\n",
    "             'í˜„ì‹¤','ìµœê³ ','ì–¼êµ´','ëŒ“ê¸€','ê¸°ì–µ','ë¯¸ì¹œ','ê¿€','ë“œë””ì–´','ë‚˜ì™”','ì‘í™”',\n",
    "            'êµ¿','ì‚¬ì´ë‹¤','ëŒ€ë‹¨','ì‹œí‚¤','ë¬´ì„­','ì£¼í–‰','ìƒê¸°','ìš°ì™€','ì˜¬ë¼ê°€','íë§',\n",
    "            'ë”°ëœ»','ë§¤ì£¼','ê·€ì—¬','ì„¤ë ˆ','ê´€ì‹¬','ì´ì˜','íŒ¬','ë¦¬ë©”ì´í¬','ê³µê°','ì†Œì‹',\n",
    "            'ì˜ˆìœ','ì¶”ì–µ','ë¶€ë“¤ë¶€ë“¤','ê·€ì—¬ìš´','í‘í‘','ì˜¤ì§€','ëŒ€ì‘','ì©”','ëª¨ì…”','íƒ„íƒ„',\n",
    "            'ì˜ˆìƒ','ë‹´ë‹¹ì','ë°˜ê°‘','ê°€ì…¨ìœ¼ë©´','í˜„ê¸°ì¦','ì˜ìƒê¸´','ì„¸ê³„ê´€','ì™„ê²°','ì™œ',\n",
    "            'ê°€ì¦ˆì•„','ìŠ¹ê²©','ìƒˆë¡œ','ê³ ì¹¨','ê·€ì—¬ì›€','ìŠ¬í”„','í—¤ì–´ì§€','ëë‚˜','ëª°ì…','ê°€',\n",
    "            'ë‹µë‹µ','ì·¨í–¥','ë§¤ë ¥','ë°œì•”','ê¹œì°','ì´ìƒ','ì‹«','ì„¤ì •','í”¼ë“œë°±','í‘œì ˆ','ë­',\n",
    "             'ì•','ë‚´ìš©','ì›”','ë”','ì‚¬ëŒ','ëœ','ìƒê°','ë² ë„','ã…','ìµœê°•','ë„ì „','ëª¨ë¥´',\n",
    "            'ë§','ì†Œë¦„','ì´ë²ˆ','í˜„ì‹¤','ã…‹','ì¬ë¯¸ìˆ','ì–¼ë¥¸','ìºë¦­í„°','ê¶ê¸ˆ','ì „ê°œ','ê¿€',\n",
    "            'ì²˜ìŒ','ë¶„ìœ„ê¸°','ìµœê³ ','ëŒ€ì‘','ëŒ“ê¸€','ì·¨í–¥','ì¡´','ê·€ì—¬ì›Œ','ë²Œì¨','ê³„ì†',\n",
    "            'ë¯¸ì³¤','ì†Œì¬','ë¶„ëŸ‰','ë“œë””ì–´','ë¯¸ì¹œ','ê¸°ë‹¤ë¦¬','ì‘í™”','ì›ƒê¸°','ì´ë»ìš”','ì§„ì‹¬',\n",
    "            'ëŠë‚Œ','ë‘ê·¼ë‘ê·¼','ì—´ì‹¬íˆ','ë¬´ì„œì›Œ','í—‰','ì˜¬ë ¤','ì‹œì‘','í¥ë¯¸','í¥ë¯¸ì§„ì§„',\n",
    "            'ì–´ì„œ','ë¬´ì„­','êµ¿','ì˜¤ëœë§Œ','ìƒ‰ê°','ê°œê·¸','ë°ë ¤ê°€','ì¿ í‚¤','ìœ„','ì˜ˆì˜',\n",
    "            'ì˜ˆë»ìš”','ìƒê°ë‚˜','ë°œì•”','ì´ì•¼ê¸°','ì ì ','ë³„ì ','ì¬ë¯¸','ê´€ì‹¬','ë§¤ë ¥',\n",
    "            'ê°‘ì‹œë‹¤','ê´œì°®','ëª°ì…','ìŠ¤íƒ€ì¼','ë°°ê²½','ë””í…Œì¼','íŒ¬','ì™œ','ê·€ì—¬ì›Œ','ë”',\n",
    "            'ê·¸ë¦¬','ì‹ ì„ ','ì›ƒ','ì—°ì¶œ','ê¸°ë¶„','ê¿ˆ','íŒ¬','ì¥ë©´','ë¹„ìŠ·','ë”°ëœ»','ì›ƒê¸°','ìƒ‰ê°',\n",
    "            'ì„±ê²©','ì°¸ì‹ ','ì˜¬ë¦¬','ëª°ì…','ì„¤ì •','ê¾¸ì¤€íˆ','ìƒˆë¡œìš´','ì§§','ê·€ì‹ ','ê°œê·¸',\n",
    "            'ì£¼ì œ','ê°œê·¸','ì¥ë¥´','íë§','ì‹¤í™”','ëª…ì‘','ë¬´ì„­','ê°ì •','ë‘ê·¼ë‘ê·¼','ë¶ˆìŒ',\n",
    "            'ì‹ ê¸°','ì¬ë¯¸ë‚˜','ë§¤ì£¼','ë² ìŠ¤íŠ¸','ì©”','ì•„ì‰½','ë…íŠ¹','ì¶”ì²œ','ì„¸ê³„ê´€','ìŠ¬í”„',\n",
    "            'ì›í•©ë‹ˆë‹¤','ê·€ì—¬ìš°','ì›ƒê²¨','ê°ë™','ë“±ë¡','ê·€ì—¼','ê°ì„±','ë³„ë¡œ','ì•Œë¦¼','ì›ƒê²¨ìš”',\n",
    "            'ì¢‹ì•„í•˜','ê·€ì—¬ì›Œì„œ','ê°œì„±','ê³ í€„'}\n",
    "\n",
    "wordsList = list(wordsList)\n",
    "wordsList.sort()\n",
    "print(wordsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentData2['comment'] = commentData2['comment'].str.replace(' ã…‹',' ã…‹ã…‹')\n",
    "commentData2['comment'] = commentData2['comment'].str.replace(' ã…',' ã…ã…')\n",
    "commentData2['comment'] = commentData2['comment'].str.replace('ê°€ì…¨ìœ¼ë©´','ê°€')\n",
    "commentData2['comment'] = commentData2['comment'].str.replace('ê°‘ì‹œë‹¤','ê°€')\n",
    "commentData2['comment'] = commentData2['comment'].str.replace('ê·€ì—¬ìš°','ê·€ì—½')\n",
    "commentData2['comment'] = commentData2['comment'].str.replace('ê·€ì—¬ìš´','ê·€ì—½')\n",
    "commentData2['comment'] = commentData2['comment'].str.replace('ê·€ì—¬ì›€','ê·€ì—½')\n",
    "commentData2['comment'] = commentData2['comment'].str.replace('ê·€ì—¬ì›Œì„œ','ê·€ì—½')\n",
    "commentData2['comment'] = commentData2['comment'].str.replace('ê·€ì—¼','ê·€ì—½')\n",
    "commentData2['comment'] = commentData2['comment'].str.replace('ê·€ì—¬ì›Œ','ê·€ì—½')\n",
    "commentData2['comment'] = commentData2['comment'].str.replace('ê·€ì—¬','ê·€ì—½')\n",
    "commentData2['comment'] = commentData2['comment'].str.replace('ê·¸ë¦¬','ê·¸ë¦¼')\n",
    "commentData2['comment'] = commentData2['comment'].str.replace('ê¸°ë‹¤ë ¸','ê¸°ë‹¤ë¦¬')\n",
    "commentData2['comment'] = commentData2['comment'].str.replace('ë¬´ì„œì›Œ','ë¬´ì„­')\n",
    "commentData2['comment'] = commentData2['comment'].str.replace('ë¯¸ì¹œ','ë¯¸ì³¤')\n",
    "commentData2['comment'] = commentData2['comment'].str.replace('ì˜ˆë»ìš”','ì˜ˆì˜')\n",
    "commentData2['comment'] = commentData2['comment'].str.replace('ì˜ˆìœ','ì˜ˆì˜')\n",
    "commentData2['comment'] = commentData2['comment'].str.replace('ì˜¬ë¼ê°€','ì˜¬ë ¤')\n",
    "commentData2['comment'] = commentData2['comment'].str.replace('ì˜¬ë¦¬','ì˜¬ë ¤')\n",
    "commentData2['comment'] = commentData2['comment'].str.replace('ì›ƒ','ì›ƒê²¨')\n",
    "commentData2['comment'] = commentData2['comment'].str.replace('ì›ƒê²¨ìš”','ì›ƒê²¨')\n",
    "commentData2['comment'] = commentData2['comment'].str.replace('ì›ƒê¸°','ì›ƒê²¨')\n",
    "commentData2['comment'] = commentData2['comment'].str.replace('ì´ë»ìš”','ì˜ˆì˜')\n",
    "commentData2['comment'] = commentData2['comment'].str.replace('ì´ì˜','ì˜ˆì˜')\n",
    "commentData2['comment'] = commentData2['comment'].str.replace('ì¬ë¯¸ë‚˜','ì¬ë¯¸')\n",
    "commentData2['comment'] = commentData2['comment'].str.replace('ì¬ë¯¸ìˆ','ì¬ë¯¸')\n",
    "commentData2['comment'] = commentData2['comment'].str.replace('ì¬ë°Œ','ì¬ë¯¸')\n",
    "commentData2['comment'] = commentData2['comment'].str.replace('ì¼','ì¬ë¯¸')\n",
    "commentData2['comment'] = commentData2['comment'].str.replace('ì¢‹','ì¢‹ì•„í•˜')\n",
    "commentData2['comment'] = commentData2['comment'].str.replace('í¥ë¯¸ì§„ì§„','í¥ë¯¸')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•œ ëŒ“ê¸€ ë‚´ì— ì¤‘ë³µë“±ì¥í•˜ëŠ” ë‹¨ì–´ ì •ë¦¬\n",
    "for i in range(len(commentData2)):\n",
    "    comSet = set(commentData2.loc[i,'comment'].split(' '))\n",
    "    token = ''\n",
    "    for j in range(1,len(comSet)):\n",
    "        token += ' '+list(comSet)[j]\n",
    "    commentData2.loc[i,'comment'] = token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genreList = ['daily','comic','fantasy','action','drama','pure','sensibility','thrill','historical','sports']\n",
    "genreDict = {}\n",
    "for genre in genreList:\n",
    "    genreDict[genre] = len(commentData2[commentData2['contentGenre'].str.contains(genre)].drop_duplicates('titleId'))*6\n",
    "genreDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arr = np.zeros((len(wordsList),22))\n",
    "token_ratio = pd.DataFrame(arr, columns=['public','notPublic','daily1','daily0',\n",
    "                              'comic1','comic0','fantasy1','fantasy0',\n",
    "                              'action1','action0','drama1','drama0','pure1','pure0',\n",
    "                             'sensibility1','sensibility0','thrill1','thrill0',\n",
    "                             'historical1','historical0','sports1','sports0'],\n",
    "                    index=wordsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubId = commentData[commentData['isPublic'] == 1].drop_duplicates('titleId')\n",
    "notPubId = commentData[commentData['isPublic'] == 0].drop_duplicates('titleId')\n",
    "print('ê³µì‹ì—°ì¬ ì›¹íˆ°ìˆ˜: ', len(pubId))\n",
    "print('ë¹„ê³µì‹ì—°ì¬ ì›¹íˆ°ìˆ˜: ', len(notPubId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(commentData2)):\n",
    "    tokenList = commentData2.loc[i,'comment'].split(' ')[1:]\n",
    "    for word in token_ratio.index:\n",
    "        if word in tokenList:\n",
    "            if commentData2.loc[i,'isPublic'] == 1:\n",
    "                token_ratio.loc[word,'public'] += 1/(len(pubId)*6)\n",
    "                for genre in genreList:\n",
    "                    if genre in commentData.loc[i,'contentGenre']:\n",
    "                        token_ratio.loc[word, genre + '1'] += 1/genreDict[genre]\n",
    "            elif commentData.loc[i,'isPublic'] == 0:\n",
    "                token_ratio.loc[word,'notPublic'] += 1/(len(notPubId)*6)\n",
    "                for genre in genreList:\n",
    "                    if genre in commentData.loc[i,'contentGenre']:\n",
    "                        token_ratio.loc[word, genre + '0'] += 1/genreDict[genre]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ì‹ì—°ì¬ê°€ 2ë°° ë§ì€ ë‹¨ì–´\n",
    "words1 = token_ratio[token_ratio['public'] > token_ratio['notPublic'] * 2]\n",
    "print(words1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¹„ì •ì‹ì—°ì¬ê°€ 2ë°° ë§ì€ ë‹¨ì–´\n",
    "words0 = token_ratio[token_ratio['public'] * 2 < token_ratio['notPublic']]\n",
    "print(words0.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¨ì–´ ì„ íƒ\n",
    "words0 = ['ê°ë™', 'ëª…ì‘','ë¹„ìŠ·','ìƒˆë¡œìš´','ì†Œì‹','ì•„ì‰½','ì˜¤ëœë§Œ','ì™„ê²°','ì´ì•¼ê¸°','ì§§','ì¶•í•˜']\n",
    "words1 = ['ë‚˜ìœ','ë°ë ¤ê°€','ë‘ê·¼ë‘ê·¼','ë“±ë¡','ë””í…Œì¼','ë§¤ì£¼','ë¬´ì„­','ë¯¸ì³¤','ë°œì•”','ë¶€ë“¤ë¶€ë“¤','ì‚¬ì´ë‹¤','ìƒ‰ê°','ì†Œë¦„','ì–¼ë¥¸','ì˜†','ì˜¤ì§€','ì‘í™”','ì „ê°œ','ì©”','ì¿ í‚¤','íƒ„íƒ„','í˜„ì‹¤']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. ë³€ìˆ˜ë¡œ ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleId = commentData2.drop_duplicates('titleId')['titleId']\n",
    "commentData3 = pd.DataFrame(columns= ['titleId','words0','words1'])\n",
    "commentData3['titleId'] = titleId\n",
    "commentData3.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for i in range(len(commentData3)):\n",
    "  comment_dt = commentData2['comment'][commentData2['titleId'] == commentData3.loc[i,'titleId']]\n",
    "  w0 = 0; w1 = 0\n",
    "  for com in comment_dt:\n",
    "    for word in words0:\n",
    "      if word in com: w0 += 1\n",
    "    for word in words1:\n",
    "      if word in com: w1 += 1\n",
    "  commentData3.loc[i,'words0'] = w0\n",
    "  commentData3.loc[i,'words1'] = w1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentData3.to_csv('comment_words.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
